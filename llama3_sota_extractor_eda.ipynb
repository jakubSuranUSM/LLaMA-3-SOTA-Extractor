{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLaMA 3 SOTA Extractor EDA\n",
    "This notebook provides two examples of SOTA extraction using LLaMA 3 in two steps. One example is a case where the paper does not report TDMS tuples and other example reports TDMS tuples. The two examples originate from the validation split of the SOTA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latex_extractor import extract_content, extract_all_sections, get_section_name\n",
    "from llama3_extractor import summarize_section, final_extraction\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device(\"cuda\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    torch.set_default_device(\"cpu\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tdms_path = 'sota/dataset/validation/0705.1367/0705.1367.tex'\n",
    "tdms_path = 'sota/dataset/validation/2110.01997v1/2110.01997v1.tex'\n",
    "tdms_annotations_path = 'sota/dataset/validation/2110.01997v1/annotations.json'\n",
    "with open(tdms_annotations_path) as f:\n",
    "    tdms_annotations = f.read() \n",
    "\n",
    "content = extract_content(tdms_path)\n",
    "content = content.replace('\\t', ' ')\n",
    "content = content.replace('\\n', ' ')\n",
    "sections = extract_all_sections(content)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d585d040846a40799cc6877cf578021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Introduction\n",
      "Related Works\n",
      "The Proposed Method\n",
      "Metrics\n",
      "Experiments\n",
      "Results\n",
      "Conclusion\n",
      "Summary\n",
      "Training\n",
      "Connectivity metric\n",
      "Lane graph results\n"
     ]
    }
   ],
   "source": [
    "for section in sections:\n",
    "    print(get_section_name(section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Results Section:\n",
      "{Results}    \\caption{Precision/Recall vs thresholds. Thresholds are uniformly sampled in [0.01, 0.1] (normalized coordinates) with 0.01 increments. In our resolution, 0.01 corresponds to 50cm.  } Since our method produces a road network graph as well as dynamic object instance estimations, we divide the results into two subsections, studying those them individually.  \\subsection{Lane graph}  The obtained results are provided in Tab.~\\ref{tab:lane_compare} and Fig.~\\ref{fig:prec-recall}, where our method achieves the best results in all metrics when compared to the baselines. The performance of PINET is lower, as expected, since the centerlines are obtained through processing lane boundaries. From the Poly(Est) vs Poly(GT) results, it can be seen that the localization of initial points is very difficult. Our method produces better precision-recall than Poly(Est), and the difference in detection and connectivity scores are significant. It is not surprising that Poly(Est) suffers in the connectivity metric, particularly connectivity recall. This metric is closely related to detection score, and missed centerlines are penalized. Our method's performance in connectivity precision against Poly(GT) combined with the detection scores shows that our method produces much fewer false-positive associations in the detected sub-graph and more accurately estimates the graph. The superiority of Poly(GT) in precision-recall and detection metrics is expected. Since most centerlines are relatively short and divergence from the initial point is limited, knowing GT initial points provides a clear advantage. However, its performance validates the strength of the  chosen baselines.   \\begin{table}[ht] \\begin{center} { \\tabcolsep=0.08cm \\begin{tabular}{ |c|c|c|c|c|c|c| } \\hline Method & M-Pre & M-Rec & Detect & C-Pre & C-Rec & C-IOU  \\\\ \\hline PINET & 54.1 & 45.6 & 19.2 & - & -& -\\\\  Poly(Est) & 54.7 & 51.2 & 40.5 & 58.4 & 16.3 & 14.6\\\\ Ours& \\textbf{60.7} & \\textbf{54.7}& \\textbf{60.6} & \\textbf{60.5} & \\textbf{52.2}&\\textbf{38.9} \\\\ \\hline Poly(GT) & 70.0 & 72.3& 76.4 &53.8 & 52.0& 36.0\\\\ \\hline \\end{tabular} } \\end{center} \\caption{Lane graph results. M-Prec and M-Recall indicate mean of the sampled points of precision-threshold and recall-threshold curves, see Fig.~\\ref{fig:prec-recall}. C-Prec and C-Rec refer to connectivity precision and recall, while C-IOU is connectivity TP/(TP + FP + FN).} \\label{tab:lane_compare} \\end{table}   \\caption{Visual results for object detection where we present the raw and refined estimates. We also show the road network estimates.  *}  Visual results for lane graphs are given in Fig.~\\ref{fig:lane-visual}. Visual inspection shows that our method generally produces better results. In the last image, our method misses some centerlines. Overall, our method produces more faithful representations. On the other hand, Poly(GT) produces centerlines that are somewhat close, in the Euclidean sense, to the matched GT lines. However, the overall graph estimation is worse than ours. This shows the power of the connectivity metric where our method surpasses Poly(GT).           \\begin{table*}[ht]  \\begin{center} { \\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c| } \\hline Method & M-pre & M-rec& detec & Con-IOU & car & truck & bus & ped & motor & bike & obj-mean\\\\ \\hline Large &  57.2 & 53.9& 58.8 & 41.0 & 20.0 & \\textbf{11.7} &13.9 &  1.9 & 2.2 & 1.4 & 8.5\\\\ Large + Split&   59.9 & \\textbf{56.8} & 52.8 & 40.8 & 20.0 & 10.1 & 16.8 &   1.9 & 2.8 & 0.8 &  8.7\\\\  Large + Split Log & \\textbf{60.7} & 54.7 & 60.6 & 38.9 & 21.8 & 11.0 & 14.5 &  2.1 & 3.8 & 2.1 &  9.2\\\\    Small & 58.2 & 54.2 & 61.2 & \\textbf{41.9} & 22.0 & 10.7 &15.1  & 2.0 & 2.9 & 1.7&  9.1 \\\\  Small+Split & 57.5 & 54.2 & 60.9 & 41.3 & 20.6 & 10.1 &14.0 &  2.0 & \\textbf{4.1} & 2.3 & 8.9 \\\\ Small+Split Log & 58.9 & 53.6 & \\textbf{61.5} & 37.8 & \\textbf{22.6} & 10.9 & \\textbf{17.6}  & \\textbf{2.4} & 3.2 & \\textbf{2.9}  & \\textbf{9.9}\\\\ \\hline \\end{tabular} } \\end{center} \\caption{Ablations are carried out on six models that test the performance contribution of the model size and positional embeddings. Object results are without refinement net and in the form of mIOU.} \\label{tab:ablation} \\end{table*}  \\subsection{Objects}  In Tab.~\\ref{tab:object_results}, the refinement net outputs of our network are compared against SOTA methods. Other methods usually produce estimates for slightly more classes. However, considering that we produce structured instance outputs along with lane graphs, we chose the most common yet comprehensive set of classes. Our method surpasses PON in half of the classes and in the mean measure. Especially, the difference in the ``car\" category is rather significant. \\begin{table}[ht]  \\begin{center} \\scriptsize{ \\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c|c|c|c|c| } \\hline Method &  car & truck & bus &   ped & motor & bike & mean\\\\ \\hline  VED &  8.8 & 0.2 & 0.0 &  0.0&  0.0&0.0&  1.5 \\\\  VPN &  25.5 & \\textbf{17.3} & 20.0 &   7.1& 5.6 & 4.4 & 13.3 \\\\  PON &  24.7 & 16.8 & 20.8 &  \\textbf{8.2}& 7.0 &\\textbf{9.4} &14.5 \\\\  Ours& \\textbf{32.5} & 15.7 & \\textbf{21.2} & 6.2 & \\textbf{7.4} & 6.4  & \\textbf{14.9}\\\\ \\hline \\end{tabular} } \\end{center} \\vspace{-.5em} \\caption{Object results in mIOU of different methods.} \\label{tab:object_results} \\end{table}  The visual results for object estimates are given in Fig.~\\ref{fig:visual-obj}. The competing methods  tend to blob segmentation and making harder to separate instances. Our refinement net outputs also suffer from the same phenomenon compared to our raw estimates. Despite of which, our refined estimates strike a good trade-off between mIOU maximization and instance separation.     \\caption{Precision/Recall vs IOU thresholds for object detection. We apply Hungarian matching with IOU to obtain corresponding estimate-GT pairs. If IOU is above the threshold, it is a true positive. Other GT objects count as false negatives, and the other estimates count as false positives.  }      \\subsection{Ablation}  We experimented with two transformer sizes. The small model has two encoder layers and tree decoder layers, while the large one has four encoder and four decoder layers. We tried using vanilla positional embeddings and our split embedding with and without taking the logarithm. The results are given in Tab.~\\ref{tab:ablation}, where the object results are in mIOU \\emph{without} refinement net. We observe that our split embedding with log helps with objects, precision and detection scores while it causes a drop in connectivity IOU. Overall, the differences are rather low. Due to its good overall performance in object and lane results, we selected the ``Large+Split Log\" model as the final one. When the object results of the selected model are compared with and without refinement net, the difference is rather significant. Refinement net boosts the performance by 5.7 points in mIOU.         \n",
      "-------------------------------------------\n",
      "Summary:\n",
      "Here is a summary of the section with an emphasis on identifying and detailing any tasks, datasets, metrics, and scores mentioned:\n",
      "\n",
      "**Tasks:**\n",
      "\n",
      "* Lane graph estimation\n",
      "* Object detection\n",
      "* Object instance estimation\n",
      "\n",
      "**Datasets:**\n",
      "\n",
      "* No specific dataset mentioned in this section\n",
      "\n",
      "**Metrics:**\n",
      "\n",
      "* Precision\n",
      "* Recall\n",
      "* Detection score\n",
      "* Connectivity precision\n",
      "* Connectivity recall\n",
      "* Connectivity IOU (Intersection over Union)\n",
      "* Mean IOU (Intersection over Union)\n",
      "\n",
      "**Scores:**\n",
      "\n",
      "* The section presents several tables with scores for different methods:\n",
      "\t+ Table 1 (Tab.~\\ref{tab:lane_compare}): Scores for lane graph estimation, including precision, recall, detection score, connectivity precision, connectivity recall, and connectivity IOU for different methods (PINET, Poly(Est), Poly(GT), and the authors' method).\n",
      "\t+ Table 2 (Tab.~\\ref{tab:ablation}): Scores for object detection, including mean IOU for different models (Large, Large + Split, Large + Split Log, Small, Small + Split, and Small + Split Log).\n",
      "\t+ Table 3 (Tab.~\\ref{tab:object_results}): Scores for object detection, including mean IOU for different\n"
     ]
    }
   ],
   "source": [
    "results = [section for section in sections if get_section_name(section) == \"Results\"][0]\n",
    "results_summary = summarize_section(results, tokenizer, model)\n",
    "\n",
    "print(\"Original Results Section:\")\n",
    "print(results)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Summary:\")\n",
    "print(results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize all sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "summaries = []\n",
    "for section in sections:\n",
    "    summaries.append(summarize_section(section, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final TDMS:\n",
      "Based on the provided summaries, here are the leaderboards extracted:\n",
      "\n",
      "[{'LEADERBOARD': {'Task': 'Lane-graph estimation', 'Dataset': 'Not explicitly mentioned', 'Metric': 'M-Pre', 'Score': '54.1'}},\n",
      " {'LEADERBOARD': {'Task': 'Lane-graph estimation', 'Dataset': 'Not explicitly mentioned', 'Metric': 'M-Rec', 'Score': '45.6'}},\n",
      " {'LEADERBOARD': {'Task': 'Lane-graph estimation', 'Dataset': 'Not explicitly mentioned', 'Metric': 'detection score', 'Score': '19.2'}},\n",
      " {'LEADERBOARD': {'Task': 'Lane-graph estimation', 'Dataset': 'Not explicitly mentioned', 'Metric': 'M-Prec', 'Score': '54.7'}},\n",
      " {'LEADERBOARD': {'Task': 'Lane-graph estimation', 'Dataset': 'Not explicitly mentioned', 'Metric': 'M-Rec', 'Score': '51.2'}},\n",
      " {'LEADERBOARD': {'Task': 'Lane-graph estimation', 'Dataset': 'Not explicitly mentioned', 'Metric': 'detection score', 'Score': '40.5'}},\n",
      " {'LEADERBOARD': {'Task': 'Lane-graph estimation', '\n",
      "Gold labels:\n",
      "[{'LEADERBOARD': {'Task': 'Lane Detection', 'Dataset': 'nuScenes', 'Metric': 'IoU', 'Score': '0.389'}}, {'LEADERBOARD': {'Task': 'Lane Detection', 'Dataset': 'nuScenes', 'Metric': 'F1 score', 'Score': '0.560'}}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = \" \".join(summaries)\n",
    "tdms = final_extraction(summary, tokenizer, model)\n",
    "print(\"Final TDMS:\")\n",
    "print(tdms)\n",
    "print(\"Gold labels:\")\n",
    "print(tdms_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with no TDMS tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = extract_content(no_tdms_path)\n",
    "content = content.replace('\\t', ' ')\n",
    "content = content.replace('\\n', ' ')\n",
    "sections_no_tdms = extract_all_sections(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "summaries_no_tqdm = []\n",
    "for section in sections_no_tdms:\n",
    "    summaries_no_tqdm.append(summarize_section(section, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final result:\n",
      "[]\n",
      "Gold label: unanswerable\n"
     ]
    }
   ],
   "source": [
    "summary_no_tdms = \" \".join(summaries_no_tqdm)\n",
    "no_tdms = final_extraction(summary_no_tdms, tokenizer, model)\n",
    "print(\"Final result:\")\n",
    "print(no_tdms)\n",
    "print(\"Gold label: unanswerable\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
